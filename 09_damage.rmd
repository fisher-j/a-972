---
title: Bear and other damage
bibliography: ["./reference/a972.bib"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r}
require(tidyverse)
library(performance)
```

# Bear damage

## data cleaning

I'll only consider live trees.

```{r}
bd <- d_l %>%
  filter(live) %>%
  mutate(year = factor(year, ordered = FALSE)) %>%
  select(-c(h_dist, azi, x, y, cc, live, ht))
```

There are trees with "healed over" in the notes, most of these are in 2008. It makes sense if these trees are subsequently listed as not bear damaged. 

I'm assuming that any tree that goes from bear damaged in 2008 to not bear damaged in 2013 is in fact healed and that any damage in 2018 is new damage.

```{r}
# # Use this to look at any "healed" trees
# bd %>% 
#   group_by(tree_id) %>%
#   filter(any(str_detect(tolower(notes), "healed"))) %>%
#   color_groups()
```

In looking at notes, trees trees that have "old bear damage" recorded are treated inconsistently, some are recorded with bear damage, some without. I'll assume that trees recorded as not bear damaged are either undamaged or completely healed, and subsequent damage implies a new bear incidence of bear damage.

```{r}

# # Use this to look at any "old bd" trees
# bd %>% 
#   group_by(tree_id) %>%
#   filter(any(str_detect(tolower(notes), "old"))) %>%
#   color_groups()

```

Are there trees that are recorded as bear damaged in one period and then not in the next period? Put another way, are bear damaged trees dropped from the list for one reason or another? 

There are 64 trees that are dropped (all in 2013), of these, 14 are subsequently listed as damaged (all in 2018). As stated above, I will consider these valid occurrences of new damage.

```{r}
bear_dropped <- bd %>%
  group_by(tree_id) %>%
  mutate(bear_dropped = lag(bear) & !bear) %>%
  filter(any(bear_dropped)) %>%
  mutate(id = cur_group_id()) %>%
  relocate(id) %>%
  arrange(id)

# # all dropped bear damage trees occur in 2013
# filter(bear_dropped, bear_dropped) %>% pull(year) %>% unique()

# color_groups(bear_dropped)

# # trees that are re-attacked
# bear_dropped %>%
#   filter(any(bear & !lag(bear))) %>%
#   mutate(id = cur_group_id(), .before = 1) %>%
#   color_groups()

```

I need to create another variable which indicates if the damage is new for that period, when a trees goes from undamaged to damaged. I will also count trees as new bear damage when the damage increases from one period to the next ie. when condition code increases from 17 or 18 to 19 or 20.

```{r}

# # this was used for ensuring all bear damage stuck with a tree throughout its life
# # I've since decided to allow trees to "completely heal," as the data seems to suggest this
# cum_logic <- function(x) {
#   if (any(x)) {
#     idx <- min(which(x))
#     x[idx:length(x)] <- TRUE
#   }
#   return(x)
# }

bd <- bd %>%
  group_by(tree_id) %>%
  mutate(
    bear_mag = as.numeric(get_cond(17, 18, 19, str = TRUE)),
    bear_new = bear & year %in% c("init", "08") | bear & !lag(bear) | bear_mag > lag(bear_mag),
    bear_new = if_else(is.na(bear_new), FALSE, bear_new)
    ) %>%
  select(-bear_mag) %>%
  ungroup()

```

I'm going to drop alder and hemlock from the analysis, because they are never attacked by bear. I'm also going to group Douglas-fir and spruce together as "other".

```{r}

bd <- filter(bd, spp %in% c("SESE3", "PSMEM", "PISI")) %>%
  mutate(spp2 = if_else(spp == "SESE3", spp, "OTHER"))

```

## Summary

Here is percent new bear damage over time. The H40 and L40 treatments seem to have the largest increases.

In the H40 treatment there is a decline in percent new bear damage in two plots, whereas for the L40 treatment, only one declines, and it is anomalous in that is the only plot that sees an increase from 2008 to 2013.

```{r}

bear_plot <- function(data, var) {
  my_dodge = position_dodge(width = 0.5)
  ggplot(data, aes(year, {{var}}, color = treatment, group = treatment)) + 
    geom_line(position = my_dodge) +
    geom_point(position = my_dodge) +
    geom_errorbar(aes(ymin = {{var}} - se, ymax = {{var}} + se), width = 0.2, position = my_dodge)
}

bd %>%
  # filter(year != "init") %>%
  group_by(year, treatment, plot) %>% 
  summarize(pct_bear = sum(bear_new, na.rm = TRUE) / n()) %>% 
  summarize(avg_pct_bear = mean(pct_bear), se = sd(pct_bear) / sqrt(n()) ) %>% 
  bear_plot(avg_pct_bear) +
    labs(title = "Average percent new bear damage for each treatment ±SE")


bd %>%
  # filter(year != "init") %>%
  group_by(year, treatment, plot) %>% 
  summarize(cnt_bear = sum(bear_new, na.rm = TRUE)) %>% 
  summarize( avg_cnt_bear = mean(cnt_bear), se = sd(cnt_bear) / sqrt(n()) ) %>% 
  bear_plot(avg_cnt_bear) +
    labs(title = "Average count new bear damage for each treatment ±SE")

bd %>%
  filter(year != "init") %>%
  group_by(year, treatment, plot) %>% 
  summarize(pct_bear = sum(bear_new, na.rm = TRUE) / n()) %>% 
  # summarize(avg_pct_bear = mean(pct_bear)) %>% 
  ggplot(aes(year, pct_bear, color = treatment, group = plot)) + 
    geom_line(position = position_dodge(width = 0.4), size = 1, alpha = 0.6) +
    facet_wrap(~ treatment) +
    theme(legend.position = "none") +
    geom_point(position = position_dodge(width = 0.4)) +
    scale_x_discrete(expand = expansion(mult = 0.2)) +
    labs(title = "Actual percent new bear damage for each treatment")

bd %>%
  filter(year != "init") %>%
  group_by(treatment, year, plot) %>%
  summarize(bear_new = sum(bear_new)) %>%
  ungroup() %>%
  ggplot(aes(str_extract(plot, "\\d"), bear_new, fill = year)) + 
    geom_col(position = "dodge", color = "black") +
    facet_wrap(~ treatment) +
    labs(
      title = "Actual count new bear damage for each plot in treatment",
      y = "Count of bear damage", x = "Plot number"  
    )

bd %>%
  filter(year != "init") %>%
  group_by(treatment, year, spp2) %>%
  summarize(bear_new = sum(bear_new)) %>%
  ungroup() %>%
  ggplot(aes(treatment, bear_new, fill = fct_relevel(spp2, "SESE3"))) + 
    geom_col(position = "stack", color = "black") +
    facet_wrap(~ year) +
    labs(
      title = "Total sum of new bear damage for each treatment/species",
      y = "Count of bear damage",
      x = "Treatment",
      fill = NULL
    )


bd %>%
  group_by(treatment, year, plot) %>%
  summarize(bear_new = sum(bear_new)) %>%
  ggplot(aes(year, bear_new, group = str_extract(plot, "\\d"))) + 
    geom_point(position = position_dodge(0.3), alpha = 0.5) +
    geom_line(position = position_dodge(0.3), size = 1, alpha = 0.5) +
    facet_wrap(~ treatment) +
    labs(
      title = "Actual count new bear damage for each plot in treatment",
      y = "Count of bear damage", x = "Year"  
    )

```

## Modeling

There are several potential to modeling this data.

1. Probability of bear damage could be modeled as binary data with a generalized linear model binomial regression with logit link (logistic regression). This, I think would be answering: for a random (average?) tree from a given treatment, what is the probability that it would be bear damaged? I'm not sure we have sufficient observations of damaged trees characterize the distribution. In the case of prediction, we may need to make adjustment for the [imbalance of response](https://stats.stackexchange.com/questions/6067/does-an-unbalanced-sample-matter-when-doing-logistic-regression)

2. Another approach is modeling *percent bear damage* at the plot level. Here linear regression may work, but theoretically, our response is bound by (0, 1). One recommendation here is [Beta regression](https://hansjoerg.me/2019/05/10/regression-modeling-with-proportion-data-part-1/).

3. Also at the plot level, we could model counts using Poisson or negative binomial GLMM. This would answer the question: how many trees can we expect to be bear damaged given a treatment. Here it would probably be important to account for differences between treatments like diameter increment and tree size.

# Logistic regression

We are modeling occurrence of new bear damage in 2013 and 2018. New bear damage in 2008 is not really comparable as it represents accumulated damage over an unspecified amount of time prior to treatment.

My first model is additive and includes `treatment`, `year`, `d_inc2`, `spp2` and random slopes for `plot`, *and* `tree_id`.


```{r, warning=TRUE}

bdmd <- subset(bd, year %in% c("13", "18"))


bm1 <- glmer(
  bear_new ~ treatment + year + d_inc2 + spp2 + (1 | plot) + (1 | tree_id),
  family = binomial,
  data = bdmd
  )

summary(bm1)

```

check `allFit` output

```{r}

bm1.all <- allFit(bm1)

summary(bm1.all)

```

For model 2, I'll remove `tree_id` and see if there is any difference.

```{r}
bm2 <- glmer(bear_new ~ treatment + year + d_inc2 + spp2 + (1 | plot), family = binomial, data = bdmd)

summary(bm2)
```

Having a look at the initial model. Including `tree_id` as a random effect doesn't seem to contribute anything to the model, so I focus on models with `plot` only.

```{r}

compare_performance(bm1, bm2) %>% kbl2(caption = "performance metrics for two initial models")

b2_mean <- emmeans(bm2, ~ treatment, type = "response")

plot(b2_mean) + 
  labs(title = "Back-transformed estiamtes and CI's averaged over year and species mod 2 (no tree_id)")
```

Redwood is clearly more targeted.

```{r}

emmeans(bm2, pairwise ~ spp2, type = "response")

```

Here we can see explicit comparisons between treatments

```{r}

pairs(b2_mean)

pwpp(b2_mean)

b2_mean %>% multcomp::cld(reversed = TRUE)

```

Finally, here is the expected response over levels of diameter increment.

```{r}

emmip(bm2, treatment ~ d_inc2, at = list(d_inc2 = seq(-0.5, 2.8, 0.1)), type = "response")

```

This model seems to be working. Now I'll do more model selection, testing for interactions. All of these models will include `plot` as the only random effect. I compare performance metrics using the R package: performance [@ludeckePerformancePackageAssessment2021]

```{r, warning=TRUE}

fl <- list(
    bear_new ~ treatment + year + spp2 + d_inc2
  , bear_new ~ treatment + year + spp2 + scale(ba_inc2)
  , bear_new ~ treatment + year + spp2 + d_inc2 + year:spp2
  , bear_new ~ treatment + year + spp2 + scale(ba_inc2) + year:spp2
  , bear_new ~ treatment + year + spp2 + d_inc2 + treatment:spp2
  , bear_new ~ treatment + year + spp2 + scale(ba_inc2) + treatment:spp2
  , bear_new ~ treatment + year + spp2 + d_inc2 + treatment:year
  , bear_new ~ treatment + year + spp2 + scale(ba_inc2) + treatment:year
  , bear_new ~ treatment + year + spp2 + d_inc2 + spp2:d_inc2
  , bear_new ~ treatment + year + spp2 + scale(ba_inc2) + spp2:scale(ba_inc2)
)

data.frame(form = sapply(fl, format)) %>% 
  kbl2(row.names = TRUE,
  caption = "Formulas testing different tree-growth variables and intereactions")

bdml <- lapply(fl, \(x) {
  glmer(
    update(x, ~ . + (1 | plot)),
    family = binomial(),
    data = bdmd,
    control = glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))
  )
})

do.call(compare_performance, c(bdml, rank = TRUE)) %>%
  kbl2(digits = 3)
```

This output is interesting, but there were some warnings from the model function about models being unidentifiable, I attempted to fix this by scaling the ba_inc variable, but this didn't help. There is more advice [here](https://stackoverflow.com/questions/53834754/scaling-predictors-in-lme4-glmer-doesnt-resolve-eigenvalue-warnings-neither-do) that I need to read.

```{r, eval=FALSE}
a <- glmer(bear_new ~ treatment + year + spp2 + d_inc2 + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + scale(ba_inc2) + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + d_inc2 + year:spp2 + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + scale(ba_inc2) + year:spp2 + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + d_inc2 + treatment:spp2 + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + scale(ba_inc2) + treatment:spp2 + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + d_inc2 + treatment:year + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + scale(ba_inc2) + treatment:year + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + d_inc2 + spp2:d_inc2 + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
a <- glmer(bear_new ~ treatment + year + spp2 + scale(ba_inc2) + spp2:scale(ba_inc2) + (1 | plot), data = bdmd, family = binomial, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
```

## Model validation

I can check for over dispersion, and [I don't think I need to worry about underdispersion](https://stats.stackexchange.com/questions/568407/how-to-correct-underdispersion-in-logistic-regression)

```{r}


```